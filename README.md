# Evaluaci√≥n M√≥dulo 7: Despliegue y Monitoreo Continuo para una Plataforma de Navegaci√≥n Portuaria

Este repositorio contiene la soluci√≥n propuesta para la evaluaci√≥n final del m√≥dulo "Despliegue y Monitoreo Continuo". El objetivo es dise√±ar una estrategia completa de CI/CD, IaC, monitoreo y ChatOps para la plataforma ficticia "PortTrack".

**Nota Importante:** Siguiendo los requisitos, este proyecto es una **implementaci√≥n te√≥rica**. Se han creado todos los artefactos de c√≥digo, configuraci√≥n y pipelines, pero no se han desplegado los recursos en la nube.

## üìù Informe T√©cnico y Justificaci√≥n de Decisiones

### 1. Estrategia de Despliegue Continuo (1.5 Puntos)

#### 1.1. Selecci√≥n del Tipo de Despliegue: Blue-Green

Para una plataforma cr√≠tica como PortTrack, donde el tiempo de inactividad puede afectar operaciones portuarias, se ha seleccionado una estrategia de despliegue **Blue-Green**.

* **Justificaci√≥n:**
  * **Cero Downtime:** Permite desplegar una nueva versi√≥n (Green) junto a la versi√≥n estable (Blue) sin afectar el tr√°fico de producci√≥n. La transici√≥n se realiza de manera instant√°nea cambiando la ruta del balanceador de carga.
  * **Rollback Inmediato:** En caso de fallo en la nueva versi√≥n, el rollback es tan simple como revertir el cambio en el balanceador de carga para que apunte nuevamente al entorno Blue, minimizando el impacto.
  * **Pruebas en un Entorno Id√©ntico al de Producci√≥n:** El entorno Green puede ser sometido a pruebas de humo y validaci√≥n finales antes de recibir tr√°fico real, asegurando su estabilidad.

#### 1.2. Justificaci√≥n de Herramientas CI/CD: GitHub Actions

Se ha elegido **GitHub Actions** como el motor de CI/CD.

* **Justificaci√≥n:**
  * **Integraci√≥n Nativa:** Al estar integrado directamente en GitHub, elimina la necesidad de herramientas externas y simplifica la configuraci√≥n.
  * **Ecosistema Robusto:** Cuenta con un marketplace de acciones reutilizables (ej. `actions/checkout`, `aws-actions/configure-aws-credentials`, `hashicorp/setup-terraform`) que acelera el desarrollo del pipeline.
  * **Gesti√≥n de Secretos:** Proporciona un sistema seguro y f√°cil de usar para gestionar credenciales y secretos a nivel de repositorio y entorno.
  * **Entornos de Despliegue:** Permite definir entornos protegidos (ej. "production") que pueden requerir aprobaciones manuales antes de un despliegue, lo cual es una pr√°ctica de seguridad fundamental.

#### 1.3. Estrategias de Rollback y Recuperaci√≥n

* **Rollback de Aplicaci√≥n:** Como se mencion√≥, la estrategia Blue-Green es la principal herramienta de rollback. Si la versi√≥n Green falla, el balanceador de carga se redirige inmediatamente a la versi√≥n Blue.
* **Rollback de Infraestructura:** Al usar Terraform, cada cambio es declarativo. Si un cambio en la infraestructura (ej. una nueva pol√≠tica de seguridad) causa problemas, se puede revertir f√°cilmente a trav√©s de Git. El commit anterior que contiene el estado funcional de la infraestructura puede ser desplegado nuevamente a trav√©s del pipeline.

---

### 2. Configuraci√≥n de Entornos y Seguridad (1.5 Puntos)

#### 2.1. Diferenciaci√≥n de Entornos (DEV, STAGING, TEST, PRD)

* **DEV:** Entorno local de los desarrolladores (ej. ejecuci√≥n del servicio Node.js y el stack de monitoreo con Docker Compose).
* **STAGING:** Un entorno en AWS id√©ntico a producci√≥n pero con menos recursos. Se utiliza para las pruebas de integraci√≥n finales antes del despliegue en producci√≥n. Nuestro pipeline lo gestiona con el archivo `environments/staging.tfvars`.
* **PRD (Producci√≥n):** El entorno final donde operan los usuarios. Es gestionado por `environments/production.tfvars` y est√° protegido por una regla de aprobaci√≥n manual en GitHub Actions.

#### 2.2. Gesti√≥n de Credenciales y Secretos

La gesti√≥n de secretos se realiza utilizando **GitHub Encrypted Secrets**.

* **Implementaci√≥n:** Las credenciales de AWS (`AWS_ACCESS_KEY_ID` y `AWS_SECRET_ACCESS_KEY`) se almacenan como secretos en la configuraci√≥n del repositorio de GitHub. Los workflows `ci.yml` y `cd.yml` acceden a ellos de forma segura usando la sintaxis `${{ secrets.NOMBRE_DEL_SECRETO }}`.
* **Ventajas:** Las credenciales nunca se exponen en el c√≥digo, logs o artefactos del pipeline, cumpliendo con las mejores pr√°cticas de seguridad.

#### 2.3. Consideraciones de Seguridad en el Pipeline

* **Escaneo de Vulnerabilidades:** El workflow `ci.yml` incluye un paso que utiliza **Trivy** para escanear la imagen Docker en busca de vulnerabilidades conocidas (CVEs) en el sistema operativo y las librer√≠as. El pipeline est√° configurado para fallar si se encuentran vulnerabilidades de severidad `HIGH` o `CRITICAL`.
* **Aprobaci√≥n Manual:** El despliegue al entorno de producci√≥n en el workflow `cd.yml` est√° protegido y requiere la aprobaci√≥n manual de un revisor, evitando despliegues accidentales.
* **M√≠nimo Privilegio:** Las credenciales de AWS almacenadas en los secretos deber√≠an, en un escenario real, corresponder a un usuario IAM con los permisos m√≠nimos necesarios para ejecutar las acciones del pipeline (ej. acceso a ECR, ECS y Terraform), en lugar de un usuario con permisos de administrador.

---

### 3. Implementaci√≥n de Monitoreo Continuo (1.5 Puntos)

Se ha implementado un stack de monitoreo y observabilidad completo, demostrable localmente a trav√©s de Docker Compose.

#### 3.1. Selecci√≥n de Herramientas

* **M√©tricas (Prometheus y Grafana):** Prometheus es el est√°ndar de facto en el mundo de Kubernetes y contenedores para la recolecci√≥n de m√©tricas de series temporales. Grafana es la herramienta l√≠der para la visualizaci√≥n de estas m√©tricas en dashboards interactivos.
* **Logs (Stack ELK + Filebeat):** Elasticsearch, Logstash y Kibana forman un stack robusto y escalable para la ingesta, procesamiento y visualizaci√≥n de logs. Filebeat es un agente ligero que se encarga de recolectar los logs de los contenedores y enviarlos a Logstash.

#### 3.2. Estrategia de Manejo de Logs y M√©tricas

* **M√©tricas:** La aplicaci√≥n Node.js expone un endpoint `/metrics` utilizando la librer√≠a `prom-client`. Prometheus est√° configurado para "scrapear" este endpoint peri√≥dicamente, almacenando m√©tricas de la aplicaci√≥n (ej. `http_requests_total`) y del sistema (m√©tricas por defecto como uso de CPU/memoria).
* **Logs:** La aplicaci√≥n escribe sus logs a la salida est√°ndar (`stdout`). Filebeat, configurado con el input `container`, captura estos logs de todos los contenedores Docker en el host y los enriquece con metadatos del contenedor (nombre, ID, etc.). Luego, los env√≠a a Logstash. Logstash procesa y estructura estos logs, envi√°ndolos finalmente a Elasticsearch para su indexaci√≥n y almacenamiento.

#### 3.3. Configuraci√≥n de Alertas y Dashboards

* **Dashboards:** Se ha creado un dashboard pre-configurado para Grafana (`monitoring/grafana/provisioning/dashboards/main.json`) que se provisiona autom√°ticamente al levantar el stack. Este dashboard muestra gr√°ficos clave como "Peticiones HTTP por Segundo" y "Uso de CPU".
* **Alertas:** Aunque no se ha configurado Alertmanager en este proyecto, la estrategia ser√≠a definir reglas de alerta en Prometheus (en un archivo `alert.rules.yml`). Estas reglas definir√≠an umbrales cr√≠ticos (ej. latencia > 500ms, tasa de errores HTTP 5xx > 2%). Cuando una alerta se dispara, Prometheus la enviar√≠a a Alertmanager, que se encargar√≠a de agrupar, desduplicar y enrutar la notificaci√≥n al canal apropiado (ej. Slack).

---

### 4. Automatizaci√≥n y ChatOps (1.5 Puntos)

La integraci√≥n de ChatOps permite al equipo de DevOps interactuar con el sistema de CI/CD y monitoreo directamente desde una plataforma de chat como Slack, mejorando la colaboraci√≥n y la velocidad de respuesta.

* **Herramientas:** Se utilizar√≠a **Hubot** con el adaptador de Slack.
* **Flujos de Trabajo de ChatOps:**
  1. **Despliegue bajo demanda:**
     * **Comando:** `@PortTrack-Bot deploy barcos-service to staging`
     * **Acci√≥n:** El bot llamar√≠a a la API de GitHub para disparar el workflow `cd.yml` con los par√°metros `service=barcos-service` y `environment=staging`.
  2. **Notificaciones del Pipeline:**
     * **Acci√≥n:** Los workflows de GitHub Actions se configurar√≠an para enviar notificaciones a un canal de Slack (`#despliegues`) al inicio, √©xito o fallo de un pipeline, proporcionando visibilidad inmediata al equipo.
  3. **Gesti√≥n de Incidentes con Alertas:**
     * **Acci√≥n:** Alertmanager se configurar√≠a con un webhook para enviar las alertas cr√≠ticas a un canal de Slack (`#alertas-produccion`).
     * **Ejemplo:** Una alerta de "Alta Latencia en API de Barcos" aparecer√≠a en el canal, permitiendo al equipo iniciar inmediatamente la investigaci√≥n del incidente.

---

## üöÄ Gu√≠a de Uso y Demostraci√≥n Local

### Prerrequisitos

* Docker
* Docker Compose

### Pasos para la Demostraci√≥n

1. **Clonar el repositorio:**

   ```bash
   git clone <URL_DEL_REPOSITORIO>
   cd <NOMBRE_DEL_DIRECTORIO>
   ```
2. **Levantar el stack de monitoreo:**
   Desde el directorio ra√≠z del proyecto, ejecuta:

   ```bash
   docker-compose -f ./monitoring/docker-compose.yml up --build -d
   ```

   Este comando construir√° la imagen de la aplicaci√≥n y levantar√° todos los servicios de monitoreo.
3. **Acceder a los servicios:**

   * **Servicio de Barcos:** [http://localhost:8080/api/barcos](http://localhost:8080/api/barcos)
   * **M√©tricas de Prometheus:** [http://localhost:8080/metrics](http://localhost:8080/metrics)
   * **Prometheus UI:** [http://localhost:9090](http://localhost:9090)
   * **Grafana:** [http://localhost:3000](http://localhost:3000) (user: admin, pass: admin)
   * **Kibana:** [http://localhost:5601](http://localhost:5601)
4. **Generar tr√°fico:**
   Para ver las m√©tricas en Grafana, puedes generar algo de tr√°fico al servicio:

   ```bash
   # Puedes usar 'watch' o un bucle para ejecutarlo repetidamente
   curl http://localhost:8080/api/barcos
   ```
5. **Detener el stack:**

   ```bash
   docker-compose -f ./monitoring/docker-compose.yml down
   ```

---

## üèõÔ∏è Diagrama de Arquitectura

```mermaid
graph TD
    %% --- Section: Development & CI/CD ---
    Dev["Desarrollador"] -- "git push" --> Repo["GitHub Repo"];
    Repo -- "Activa" --> Pipeline_Test["1. Test & Scan"];
    Pipeline_Test -- "->" --> Pipeline_Build["2. Build & Push to ECR"];
    Pipeline_Build -- "->" --> Pipeline_Plan["3. Terraform Plan"];
    Pipeline_Plan -- "->" --> Pipeline_Approval{{"4. Aprobaci√≥n Manual"}};
    Pipeline_Approval -- "->" --> Pipeline_Deploy["5. Despliegue (Te√≥rico)"];
    
    %% --- Section: AWS Infrastructure ---
    ECR["AWS ECR"];
    Pipeline_Build -- "Push to" --> ECR;
    ALB["Application Load Balancer"];
    ECS["ECS Fargate (Servicio Node.js)"];
    RDS["RDS (Base de Datos)"];
    Pipeline_Deploy -- "Provisiona/Actualiza" --> ALB;
    Pipeline_Deploy -- "Provisiona/Actualiza" --> ECS;
    Pipeline_Deploy -- "Provisiona/Actualiza" --> RDS;
    ALB -- "Routes traffic to" --> ECS;
    ECS -- "Pulls image from" --> ECR;
    ECS -- "Connects to" --> RDS;

    %% --- Section: Users ---
    User["Usuario Final"] -- "Accede v√≠a" --> ALB;
    
    %% --- Section: Monitoring & Observability ---
    Prometheus["Prometheus"];
    Grafana["Grafana"];
    Alertmanager["Alertmanager"];
    Filebeat["Filebeat"];
    Logstash["Logstash"];
    Elasticsearch["Elasticsearch"];
    Kibana["Kibana"];
    
    ECS -- "Expone M√©tricas" --> Prometheus;
    Prometheus -- "Fuente de Datos" --> Grafana;
    Prometheus -- "Env√≠a Alertas" --> Alertmanager;
    
    ECS -- "Genera Logs" --> Filebeat;
    Filebeat -- "Env√≠a a" --> Logstash;
    Logstash -- "Procesa y Env√≠a a" --> Elasticsearch;
    Elasticsearch -- "Almacena para" --> Kibana;

    %% --- Section: ChatOps ---
    Slack["Slack"];
    Hubot["Hubot"];
    DevOps["Equipo DevOps"];
    
    Alertmanager -- "Notifica a" --> Slack;
    Pipeline_Deploy -- "Notifica a" --> Slack;
    DevOps -- "Usa" --> Hubot;
    Hubot -- "Se integra con" --> Slack;
    Hubot -- "Dispara" --> Pipeline_Test;
end
```
